{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "tensorboard_batchnorm_custom_loss_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YOmI2ciaBSd1",
        "qjP0_xnmBSd-",
        "MoDeaHNrBSd_"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9U9lqPWBSdj"
      },
      "source": [
        "# Image Classification - Tensorboard, Batch Norm and Custom Loss Functions\n",
        "In this exercise, you'll continue to work with our neural network for classifying Israeli Politicians.  \n",
        "We will use tensorboard to monitor the training process and model performance.  \n",
        "\n",
        "For the questions below, please use the network architecture you suggested in Q8 of HW1.  \n",
        "This time, we provide you with a clean dataset of Israeli Politicians, that doesn't include multiple politicians in the same image, in the folder `data/israeli_politicians_cleaned/`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq260gu0BSdp"
      },
      "source": [
        "## Tensorboard\n",
        "TensorBoard provides visualization and tooling for machine learning experimentation:\n",
        "- Tracking and visualizing metrics such as loss and accuracy\n",
        "- Visualizing the model graph (ops and layers)\n",
        "- Viewing histograms of weights, biases, or other tensors as they change over time\n",
        "- Projecting embeddings to a lower dimensional space\n",
        "- Displaying images, text, and audio data\n",
        "- Profiling programs\n",
        "\n",
        "Tensorboard worked originally with Tensorflow but can now be used with PyTorch as well.  \n",
        "You can embed a tensorboard widget in a Jupyter Notebook, although if you're not using Google Colab we recommend that you open tensorboard separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTNoTiW0BSdt"
      },
      "source": [
        "To get started with Tensorboard, please read the following pages:\n",
        "\n",
        "PyTorch related:\n",
        "1. https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
        "1. https://becominghuman.ai/logging-in-tensorboard-with-pytorch-or-any-other-library-c549163dee9e\n",
        "1. https://towardsdatascience.com/https-medium-com-dinber19-take-a-deeper-look-at-your-pytorch-model-with-the-new-tensorboard-built-in-513969cf6a72\n",
        "1. https://pytorch.org/docs/stable/tensorboard.html\n",
        "1. https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/04-utils/tensorboard\n",
        "\n",
        "Tensorflow related:\n",
        "1. https://itnext.io/how-to-use-tensorboard-5d82f8654496\n",
        "1. https://www.datacamp.com/community/tutorials/tensorboard-tutorial\n",
        "1. https://medium.com/@anthony_sarkis/tensorboard-quick-start-in-5-minutes-e3ec69f673af\n",
        "1. https://www.guru99.com/tensorboard-tutorial.html\n",
        "1. https://www.youtube.com/watch?time_continue=1&v=s-lHP8v9qzY&feature=emb_logo\n",
        "1. https://www.youtube.com/watch?v=pSexXMdruFM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_qVeHUn9ypg"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter('logs/RegularNet') # Create Tensorboard event writer will output to the relevant folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw-BoTJCDo5f"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN9wnr7KDr6d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7DSmP61BSdv"
      },
      "source": [
        "### Starting Tensorboard\n",
        "Jupyter Notebook has extensions for displaying TensorBoard inside the notebook. Still, I recommend that you run it separately, as it tends to get stuck in notebooks.\n",
        "\n",
        "The syntax to load TensorBoard in a notebook is this:\n",
        "```python\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./logs\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "503Pr4r0BSdw"
      },
      "source": [
        "In the shell, you can instead run:\n",
        "```\n",
        "tensorboard --logdir ./logs\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T03:22:21.503129Z",
          "start_time": "2020-03-12T03:22:18.807319Z"
        },
        "id": "ZlPOCeaiBSdz"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Start TensorBoard within the notebook:\n",
        "#%tensorboard --logdir ./logs"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxPTeBcXCjGX"
      },
      "source": [
        "### Load Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rdypNoTCyIG"
      },
      "source": [
        "# Create a folder for our data\n",
        "!mkdir data\n",
        "!mkdir data/israeli_politicians"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG5l9mvwC2Na"
      },
      "source": [
        "# Download our dataset and extract it\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "\n",
        "url = 'https://github.com/omriallouche/ydata_deep_learning_2021/blob/main/data/israeli_politicians_cleaned.zip?raw=true'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('./data/israeli_politicians_cleaned.zip', 'wb').write(r.content)\n",
        "\n",
        "with ZipFile('./data/israeli_politicians_cleaned.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall(path='./data/israeli_politicians/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw1VfqgjUXvP",
        "outputId": "c2158dfe-e33e-49d8-d80b-27b2d863f270"
      },
      "source": [
        "#searching files with currupt exif data and deleting them\n",
        "import glob, os\n",
        "import PIL.Image\n",
        "import warnings\n",
        "\n",
        "def get_files(folder, extension):\n",
        "  for filename in glob.iglob('{}/**/*{}'.format(folder, extension), recursive=True):\n",
        "    if os.path.isfile(filename):\n",
        "        yield filename\n",
        "\n",
        "for f in get_files(\"./data/israeli_politicians\", \"jpg\"):\n",
        "  with warnings.catch_warnings(record=True) as w:\n",
        "     img = PIL.Image.open(f)\n",
        "     exif_data = img._getexif()\n",
        "     try:\n",
        "       print(str(w[-1].message))\n",
        "       print(f)\n",
        "       os.remove(f)\n",
        "     except:\n",
        "       pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 19. Skipping tag 36867\n",
            "./data/israeli_politicians/train/naftali_bennett/image683.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxB3cOnGeQKI"
      },
      "source": [
        "def setup_seed(rnd_state=42):\n",
        "  import torch\n",
        "  import random\n",
        "  random.seed(rnd_state)\n",
        "  np.random.seed(rnd_state)\n",
        "  torch.manual_seed(rnd_state)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed_all(rnd_state)\n",
        "\n",
        "setup_seed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpOJsR1YDdlc"
      },
      "source": [
        "means = np.array([0.485, 0.456, 0.406])\n",
        "stds = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(means, stds)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(means, stds)\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qx7KoOZzD-m2",
        "outputId": "cef03e7f-98de-41f6-da84-efdc61fc7090"
      },
      "source": [
        "data_dir = r'./data/israeli_politicians/'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=16, shuffle=True, num_workers=2),\n",
        "    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=16, shuffle=False, num_workers=2)\n",
        "  }\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "print('dataset_sizes: ', dataset_sizes)\n",
        "\n",
        "class_names = image_datasets['train'].classes\n",
        "print('class_names:', class_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset_sizes:  {'train': 811, 'val': 202}\n",
            "class_names: ['ayelet_shaked', 'benjamin_netanyahu', 'benny_gantz', 'danny_danon', 'gideon_saar', 'kostya_kilimnik', 'naftali_bennett', 'ofir_akunis', 'yair_lapid']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOmI2ciaBSd1"
      },
      "source": [
        "### Show images using TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T03:22:25.305404Z",
          "start_time": "2020-03-12T03:22:22.367810Z"
        },
        "id": "dw0QZ5d1BSd1"
      },
      "source": [
        "# here we show images after transform, which normalizes them\n",
        "images, labels = next(iter(dataloaders['train'])) # get one batch of images\n",
        "grid = torchvision.utils.make_grid(images) # create a grid of these images\n",
        "writer.add_image('normalized images', grid, 0)\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WC8NLg8TH0R"
      },
      "source": [
        "def denormalize_image(img):\n",
        "    img = img.numpy().transpose((1, 2, 0)) # change from 3x256x256 to 256x256x3\n",
        "    img = stds * img + means # apply std&mean reverse transform on each channel\n",
        "    img = np.clip(img, 0, 1) # clip the results between 0 and 1\n",
        "    img = img.transpose((2, 0, 1)) # return the impage to the original form 3x256x256\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQyXHzd6JiTI"
      },
      "source": [
        "def denormalize_images(images):\n",
        "  result = []\n",
        "  for img in images:\n",
        "    result.append(denormalize_image(img)) # apply transform on one image and save it\n",
        "  return torch.tensor(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDCSPlm1KDzG"
      },
      "source": [
        "# here we perform denormalization, showing the original images\n",
        "original_images = denormalize_images(images)\n",
        "grid = torchvision.utils.make_grid(original_images) # create a grid of these images\n",
        "writer.add_image('original images', grid, 0)\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1uoYYWuBSd2"
      },
      "source": [
        "### Define the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB9xNOljOGO1"
      },
      "source": [
        "# define abstract model class with fit, predict and forward methods\n",
        "class AbstractModel(nn.Module):\n",
        "  def __init__(self, cls2idx, *args, **kwargs):\n",
        "    super(AbstractModel, self).__init__()\n",
        "    self.cls2idx = cls2idx\n",
        "    self.num_classes= len(cls2idx)\n",
        "    self.idx2cls = {v:k for k,v in self.cls2idx.items()}\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def predict_image(self, img, return_class=False):\n",
        "    self.eval()\n",
        "    if isinstance(img, str):\n",
        "      img = PIL.Image.open(img)\n",
        "    if not torch.is_tensor(img):\n",
        "      img = data_transforms[\"val\"](img)\n",
        "    img = img.unsqueeze(0).to(device)\n",
        "    outputs = self(img) \n",
        "    if return_class:\n",
        "      _, preds = torch.max(outputs, 1) \n",
        "      return self.idx2cls[preds.item()]\n",
        "    else:\n",
        "      return outputs\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def predict(self, test_dataloaders):\n",
        "    self.eval()\n",
        "    # clear_cache()\n",
        "    preds = np.zeros((len(test_dataloaders), 1))\n",
        "    probs = np.zeros((len(test_dataloaders), self.num_classes))\n",
        "    for idx, inputs in enumerate(test_dataloaders):\n",
        "        if isinstance(inputs, list):\n",
        "          inputs = inputs[0]\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = self(inputs) \n",
        "        _, current_pred = torch.max(outputs, 1) \n",
        "        current_probs = nn.functional.softmax(outputs, dim=1)\n",
        "        preds[idx] = current_pred.item() # save the predicted class index\n",
        "        probs[idx] = current_probs.cpu() # save probs of each class\n",
        "    return preds, probs\n",
        "  \n",
        "  def init_weights(self):\n",
        "      for m in self.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_uniform_(m.weight.data)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            m.weight.data.fill_(1)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            m.weight.data.normal_(0, 0.01)\n",
        "            m.bias.data.zero_()\n",
        "\n",
        "  def fit(self, dataloaders, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    model = self\n",
        "    model.init_weights()\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  \n",
        "            else:\n",
        "                model.eval()   \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase=='train'):\n",
        "                    outputs = model(inputs) \n",
        "                    _, preds = torch.max(outputs, 1) \n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward() \n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            if phase == 'train':\n",
        "                if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
        "                  scheduler.step(epoch_loss)\n",
        "                else:\n",
        "                  scheduler.step()  \n",
        "            \n",
        "            # log stats in Tensorboard\n",
        "            writer.add_scalar('Loss/'+phase, epoch_loss, epoch) # log loss in tensorboard\n",
        "            writer.add_scalar('Accuracy/'+phase, epoch_acc, epoch) # log acc in tensorboard\n",
        "            layer_0_weights = self.features[0].weight\n",
        "            writer.add_scalar('Mean layer 0 weight', layer_0_weights.mean().item(), epoch) # log mean value of first layer weights\n",
        "            writer.add_histogram('Layer 0 weights', layer_0_weights.flatten(), epoch)    # add a historgram of first layer weights\n",
        "            writer.flush()\n",
        "\n",
        "            # save the best model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {(time_elapsed // 60):.0f}m {(time_elapsed % 60):.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "    model.load_state_dict(best_model_wts) # return model to the best state\n",
        "\n",
        "\n",
        "  def summary(self):\n",
        "    return summary(self, (3, 256, 256))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nHlxCSo40wS"
      },
      "source": [
        "class Net(AbstractModel):\n",
        "    def __init__(self, cls2idx, batchnorm=False, *args, **kwargs):\n",
        "        super(Net, self).__init__(cls2idx, *args, **kwargs)\n",
        "        self.cls2idx = cls2idx\n",
        "        self.num_classes = len(cls2idx)\n",
        "        if batchnorm:\n",
        "          self.features = nn.Sequential(\n",
        "              nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "              nn.BatchNorm2d(64),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "              nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "              nn.BatchNorm2d(192),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "              nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(384),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(256),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(256),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "          )\n",
        "        else:\n",
        "          self.features = nn.Sequential(\n",
        "              nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "              nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "              nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "            )\n",
        "          \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, self.num_classes)\n",
        "        )\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1FWwdURQGOW",
        "outputId": "96b4652c-6665-4218-f3b0-4b701a8d9a05"
      },
      "source": [
        "# Check for the availability of a GPU, and use CPU otherwise\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T03:39:13.437035Z",
          "start_time": "2020-03-12T03:39:13.433000Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkcqAsbjBSd2",
        "outputId": "9a2d046c-35cb-4ed6-fc9f-2bc81ecbc87c"
      },
      "source": [
        "cls2idx = dataloaders['train'].dataset.class_to_idx\n",
        "net = Net(cls2idx=cls2idx).to(device)\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOmm8o30z_c6"
      },
      "source": [
        "### Inspect the model graph\n",
        "You can print a network object to find useful information about it:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rWN6nJeBSd3"
      },
      "source": [
        "TensorBoard can help visualize the network graph. It takes practice to read these.  \n",
        "\n",
        "Write the graph to TensorBoard and review it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T03:22:27.132650Z",
          "start_time": "2020-03-12T03:22:27.080267Z"
        },
        "id": "Cp-ICQprBSd4"
      },
      "source": [
        "writer.add_graph(net, images.to(device))\n",
        "writer.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD3IUXldBSd4"
      },
      "source": [
        "You can also use the package `torchsummary` for a fuller info on the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T03:39:34.927085Z",
          "start_time": "2020-03-12T03:39:30.883979Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pARsRL5mBSd5",
        "outputId": "3b63a3c4-c55f-4965-82a0-8622787457f7"
      },
      "source": [
        "!pip install torchsummary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T03:40:32.330002Z",
          "start_time": "2020-03-12T03:40:32.304145Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4RPZYOtBSd6",
        "outputId": "8c952bce-2d6b-4838-c52e-42922c416c0f"
      },
      "source": [
        "channels=3; H=256; W=256\n",
        "from torchsummary import summary\n",
        "summary(net, input_size=(channels, H, W))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 63, 63]          23,296\n",
            "              ReLU-2           [-1, 64, 63, 63]               0\n",
            "         MaxPool2d-3           [-1, 64, 31, 31]               0\n",
            "            Conv2d-4          [-1, 192, 31, 31]         307,392\n",
            "              ReLU-5          [-1, 192, 31, 31]               0\n",
            "         MaxPool2d-6          [-1, 192, 15, 15]               0\n",
            "            Conv2d-7          [-1, 384, 15, 15]         663,936\n",
            "              ReLU-8          [-1, 384, 15, 15]               0\n",
            "            Conv2d-9          [-1, 256, 15, 15]         884,992\n",
            "             ReLU-10          [-1, 256, 15, 15]               0\n",
            "           Conv2d-11          [-1, 256, 15, 15]         590,080\n",
            "             ReLU-12          [-1, 256, 15, 15]               0\n",
            "        MaxPool2d-13            [-1, 256, 7, 7]               0\n",
            "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
            "          Dropout-15                 [-1, 9216]               0\n",
            "           Linear-16                    [-1, 9]          82,953\n",
            "================================================================\n",
            "Total params: 2,552,649\n",
            "Trainable params: 2,552,649\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 10.80\n",
            "Params size (MB): 9.74\n",
            "Estimated Total Size (MB): 21.29\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qvZ2GUnBSd6"
      },
      "source": [
        "## Train the network\n",
        "Next, we'll train the network. In the training loop, log relevant metrics that would allow you to plot in TensorBoard:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLrDaOe4BSd8"
      },
      "source": [
        "1. The network loss\n",
        "1. Train and test error\n",
        "1. Average weight in the first layer\n",
        "1. Histogram of weights in the first layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meLZKc96SccZ",
        "outputId": "a9725745-a00c-4077-aa44-1527071b6ed0"
      },
      "source": [
        "setup_seed()\n",
        "optimizer_ft = optim.Adam(net.parameters(), lr=0.0001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 15\n",
        "net.fit(dataloaders, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training complete in 0m 45s\n",
            "Best val Acc: 0.440594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjP0_xnmBSd-"
      },
      "source": [
        "### Precision-Recall Curve\n",
        "Use TensorBoard to plot the precision-recall curve:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwoMz5CyidYq"
      },
      "source": [
        "test_dataloader = torch.utils.data.DataLoader(datasets.ImageFolder(os.path.join(data_dir, \"val\"), data_transforms[\"val\"]), batch_size=1, shuffle=False, num_workers=2)\n",
        "y_pred, y_prob = net.predict(test_dataloader)\n",
        "y_true_idx = np.array(test_dataloader.dataset.targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu2MutLxgymu"
      },
      "source": [
        "y_pred = y_pred.flatten() # convert to 1d vector\n",
        "# plotting pr curve for each class\n",
        "for class_index in range(len(class_names)):\n",
        "    preds = (y_pred == class_index) # boolean vector identifying if the sample was predicted to belong to the current class\n",
        "    probs = y_prob[:, class_index] # take predicted probability of the current class\n",
        "    writer.add_pr_curve(class_names[class_index], preds, probs) # log a PR curve for the current class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoDeaHNrBSd_"
      },
      "source": [
        "### Display Model Errors\n",
        "A valuable practice is to review errors made by the model in the test set. These might reveal cases of bad preprocessing or lead to come up with improvements to your original model.\n",
        "\n",
        "Show 12 images of errors made by the model. For each, display the true and predicted classes, and the model confidence in its answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdgTghFXBSeA"
      },
      "source": [
        "error_indices = np.argwhere(y_pred.flatten() != y_true_idx) # get indexies of wrong predictions\n",
        "selected_12_errors = np.random.choice(error_indices.flatten(), size=12, replace=False) # get 12 random errors\n",
        "error_images = np.array(test_dataloader.dataset.samples) # load paths of all images\n",
        "\n",
        "for i, err_idx in enumerate(selected_12_errors):\n",
        "      true_class = y_true_idx[err_idx]\n",
        "      true_label = class_names[true_class]\n",
        "      incorrect_class = int(y_pred[err_idx])\n",
        "      incorrect_class_label = class_names[incorrect_class]\n",
        "      incorrect_prob = y_prob[err_idx, incorrect_class]\n",
        "      error_image_filename = error_images[err_idx][0] # take path of the current error image\n",
        "      error_image = data_transforms[\"val\"](PIL.Image.open(error_image_filename)) # load the image as array and transform it\n",
        "      error_image = denormalize_image(error_image) # return the image to original color pallette\n",
        "      title = f'true label: {true_label}, pred label: {incorrect_class_label} ({incorrect_prob:.3f})'\n",
        "      writer.add_image(title, error_image, 0)\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dNy8ALhBSeA"
      },
      "source": [
        "## Batch Normalization\n",
        "In this section, we'll add a Batch Norm layer to your network.  \n",
        "Use TensorBoard to compare the network's convergence (train and validation loss) with and without Batch Normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-12T02:02:02.225508Z",
          "start_time": "2020-03-12T02:02:02.204005Z"
        },
        "id": "QnQs75AWBSeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d704f4d8-e4ce-4a39-e882-dc04bd837781"
      },
      "source": [
        "netBN = Net(cls2idx=cls2idx, batchnorm=True).to(device)\n",
        "print(netBN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (5): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=9, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApJ1cDXOBSeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d02985-fbee-490b-e8c5-9937d5f550a8"
      },
      "source": [
        "setup_seed()\n",
        "writer = SummaryWriter('logs/BatchNorm') # Create Tensorboard event writer will output to the relevant folder\n",
        "optimizer_BN = optim.Adam(netBN.parameters(), lr=0.0001)\n",
        "exp_lr_scheduler_BN = lr_scheduler.StepLR(optimizer_BN, step_size=5, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "netBN.fit(dataloaders, criterion, optimizer_BN, exp_lr_scheduler_BN, num_epochs=15)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training complete in 0m 46s\n",
            "Best val Acc: 0.678218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQo750T6Epvi"
      },
      "source": [
        "We can see that los on both training and validation is much lower, and accuracy on both is much higher: **67%** validation accuracy with BatchNorm and **46%** without BN!\n",
        "\n",
        "Go BatchNorm!!! :-) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGzgP6DHBSeB"
      },
      "source": [
        "Use TensorBoard to plot the distribution of activations with and without Batch Normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JqgHAF8CmG4",
        "outputId": "cd54691d-15d5-47fe-8a76-6652af6522ef"
      },
      "source": [
        "def activation_hook_regular(layer, input, out):\n",
        "  writer.add_histogram('Layer 0 activations without BatchNorm', out.flatten())\n",
        "\n",
        "def activation_hook_BN(layer, input, out):\n",
        "  writer.add_histogram('Layer 0 activations with BatchNorm', out.flatten())\n",
        "\n",
        "net.features[1].register_forward_hook(activation_hook_regular) # register activation hook for logging activations of layer 0 (ReLU output) in a regular net without Batchnorm\n",
        "netBN.features[2].register_forward_hook(activation_hook_BN) # register activation hook for logging activations of layer 0 (ReLU output) - for comparison with regular model without BatchNorm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x7f3722360150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv-nfQoYGEOP"
      },
      "source": [
        "images = images.to(device) # moves a batch of images to GPU\n",
        "_ = net(images) # apply the regular model on one batch of images and log the activations\n",
        "_ = netBN(images) # apply the BatchNorm model on one batch of images and log the activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b-S_2b5IGrP"
      },
      "source": [
        "From the histogram we can see that in a model without BatchNorm, most of the the activations are between 0.05-0.16, while in BatchNormn model they are larger (scaled up) between 0.16 and 0.48"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoUnvka0BSeC"
      },
      "source": [
        "## Custom Loss Function\n",
        "Manually labeled datasets often contain labeling errors. These can have a large effect on the trained model.  \n",
        "In this task we’ll work on a highly noisy dataset. Take our cleaned Israeli Politicians dataset and randomly replace 10% of the true labels.\n",
        "Compare the performance of the original model to a similar model trained on the noisy labels. \n",
        "\n",
        "Suggest a loss function that might help with noisy labels. Following this guide, implement your own custom loss function in PyTorch and compare the model performance using it:  \n",
        "https://discuss.pytorch.org/t/solved-what-is-the-correct-way-to-implement-custom-loss-function/3568/9\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwFMfV0KsxYq"
      },
      "source": [
        "# Create a dataloader that replaces 10% of the labels in the training set\n",
        "\n",
        "@torch.no_grad()\n",
        "def mixup(alpha, data, target):\n",
        "      bs = data.size(0)\n",
        "      c = np.random.beta(alpha, alpha)\n",
        "\n",
        "      perm = torch.randperm(bs).cuda()\n",
        "\n",
        "      md = c * data + (1 - c) * data[perm, :]\n",
        "      mt = c * target + (1 - c) * target[perm]\n",
        "      return md, mt\n",
        "\n",
        "class MixUpWrapper(object):\n",
        "    def __init__(self, alpha, dataloader):\n",
        "        self.alpha = alpha\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "    def mixup_loader(self, loader):\n",
        "        for input, target in loader:\n",
        "            i, t = mixup(self.alpha, input, target)\n",
        "            yield i, t.long()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self.mixup_loader(self.dataloader)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataloader)\n",
        "\n",
        "dataloaders[\"train\"] = MixUpWrapper(0.1, dataloaders[\"train\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdzpq8zgBSeD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f9f968-d46a-4e5e-b82e-f78d1e2fa882"
      },
      "source": [
        "# Let's replace 10% of the labels in the training set and see how it affects accuracy without changing the loss function\n",
        "writer = SummaryWriter('logs/NoisyLabels') # Create Tensorboard event writer will output to the relevant folder\n",
        "netCL = Net(cls2idx=cls2idx, batchnorm=True).to(device)\n",
        "setup_seed()\n",
        "optimizer_CL = optim.Adam(netCL.parameters(), lr=0.0001)\n",
        "exp_lr_scheduler_CL = lr_scheduler.StepLR(optimizer_CL, step_size=5, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "netCL.fit(dataloaders, criterion, optimizer_CL, exp_lr_scheduler_CL, num_epochs=15) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training complete in 0m 56s\n",
            "Best val Acc: 0.470297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H8oOGXCudzV"
      },
      "source": [
        "We can see that mixing up 10% of the training labels reduced validation accuracy from 67% to 49%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OitC-HaZD_TU"
      },
      "source": [
        "# Now, let's create a class with custom loss function (LabelSmoothing), that is supposted to help in cases on noisy labels\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "    \n",
        "    def forward(self, x, target, smoothing=0.1):\n",
        "        confidence = 1. - smoothing\n",
        "        logprobs = F.log_softmax(x, dim=-1)\n",
        "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
        "        nll_loss = nll_loss.squeeze(1)\n",
        "        smooth_loss = -logprobs.mean(dim=-1)\n",
        "        loss = confidence * nll_loss + smoothing * smooth_loss\n",
        "        return loss.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ta2yeDpo7hj",
        "outputId": "62708592-5d1e-46c2-d453-8c4ee6372f9f"
      },
      "source": [
        "writer = SummaryWriter('logs/CustomLoss') # Create Tensorboard event writer will output to the relevant folder\n",
        "netCL = Net(cls2idx=cls2idx, batchnorm=True).to(device)\n",
        "setup_seed()\n",
        "optimizer_CL = optim.Adam(netCL.parameters(), lr=0.0001)\n",
        "exp_lr_scheduler_CL = lr_scheduler.StepLR(optimizer_CL, step_size=5, gamma=0.1)\n",
        "criterion = LabelSmoothingCrossEntropy() \n",
        "netCL.fit(dataloaders, criterion, optimizer_CL, exp_lr_scheduler_CL, num_epochs=15) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training complete in 0m 56s\n",
            "Best val Acc: 0.480198\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}